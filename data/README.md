# Weibo21
There are three files in this folder, i.e., ``train.pkl``, ``val.pkl`` and ``test.pkl``, which are the splited dataset used in the paper.

# gossip

There are three files in this folder, i.e., ``train.pkl``, ``val.pkl`` and ``test.pkl``, which are generated by preprocessing the new data set given in class.

raw_json: 

- gossipcop_v3-3_integration_based_fake_tn200
- gossipcop_v3-7_integration_based_legitimate_tn300

（1）【/data/gossip2merge.py】首先我们将两个数据集合并。默认Integration-based Fake中真新闻假新闻合成的内容为假新闻，Integration-based Legitimate中真新闻和真新闻合成的内容为真新闻。得到/data/merge_whole.json。总共生成8623（5926+2697）条数据。

（2）【/data/json2pkl.py】 我们根据原文的新闻分类标准使用ChatGLM-6B去生成merge_whole.json每一条数据的种类得到领域表示。若是通过llm生成则得到/data/category.json。

Prompt如下：prompt = "Please read the above paragraph and decide which topic in the folloing list ['Technology','Military','Education and Testing','Disaster incident', 'Politics', 'Medicine and Health', 'Financial Business', 'Entertainment', 'social life'] is the most relevant to the meaning of the above paragraph. You only need to choose the only one of the most relevant topic string name in the above list  and answer one topic string name in the above list to output Please Don't print anything extra, no more than 3 words."

（3）【/data/json2pkl.py】 通过生成的/data/category.json文件进行数据预处理为category_change_no2entertainment.json 后再转化为/data/gossip下的pkl文件后送入模型训练。

## Notice

Please note that the dataset may not be used for any purpose other than research.
## Access to Raw Dataset
You will be shared the raw dataset by email after an "Application to Use the Weibo21 dataset for Fake News Detection" has been submitted.
